{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Computational_Graph_and_Linear_Regression.ipynb","provenance":[{"file_id":"10ydDeQEnIER_EgTug6MF3g74FhBur2-V","timestamp":1604049604330}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"X0FIqUru_CR4"},"source":["# **INTRODUCTION**\n"]},{"cell_type":"markdown","metadata":{"id":"y9dFvmIBKUtW"},"source":["*Hiện có rất nhiều tài liệu mô tả về Computation Graph và Linear Regression trên mạng và mình xin phép để một vài đường link để mọi người cùng tham khảo*"]},{"cell_type":"markdown","metadata":{"id":"V_fhyGw3_GOp"},"source":["##**1.Computational Graph**\n","Đồ thị tính toán\n"]},{"cell_type":"markdown","metadata":{"id":"ZSRqRvRAIG0P"},"source":["1.https://aivietnam.ai/courses/aisummer2019/lessons/computational-graph/"]},{"cell_type":"markdown","metadata":{"id":"njGjWTFqIakW"},"source":["2.https://colah.github.io/posts/2015-08-Backprop/"]},{"cell_type":"markdown","metadata":{"id":"MMYI6AjFJJTF"},"source":["3.https://www.deepideas.net/deep-learning-from-scratch-i-computational-graphs/"]},{"cell_type":"markdown","metadata":{"id":"9i-NMtTDKMlO"},"source":["4.https://www.tutorialspoint.com/python_deep_learning/python_deep_learning_computational_graphs.htm"]},{"cell_type":"markdown","metadata":{"id":"7jzhXldTa4D5"},"source":["##**2.LinearRegression**\n","Hồi quy tuyến tính"]},{"cell_type":"markdown","metadata":{"id":"ppy54cZmLaq0"},"source":["1.https://www.tutorialspoint.com/machine_learning_with_python/regression_algorithms_linear_regression.htm"]},{"cell_type":"markdown","metadata":{"id":"aLB3mOjkLhiO"},"source":["2.https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html"]},{"cell_type":"markdown","metadata":{"id":"jdfT2asGbQBg"},"source":["## **3.Một số ví dụ trong bài giảng**"]},{"cell_type":"markdown","metadata":{"id":"e6CN3UAJLxJe"},"source":["####**DATASET:**[Here](https://drive.google.com/drive/folders/1iyER0iU3PckcHeb_ShbJGY-RIJeyltRs)"]},{"cell_type":"markdown","metadata":{"id":"DOy5tJf8OXcM"},"source":["####**Simple linear regression_stochastic**"]},{"cell_type":"code","metadata":{"id":"9RL9Ak20PAde"},"source":["import numpy as np\n","from numpy import genfromtxt\n","import matplotlib.pyplot as plt\n","\n","data = genfromtxt('data.csv', delimiter=',')\n","areas  = data[:,0]\n","prices = data[:,1]\n","print(data)\n","\n","plt.scatter(areas, prices)\n","plt.xlabel('Diện tích nhà (x 100$m^2$)')\n","plt.ylabel('Giá nhà (chục lượng vàng)')\n","plt.xlim(3,7)\n","plt.ylim(4,10)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QvPp1SeQPDYS"},"source":["import numpy as np\n","from numpy import genfromtxt\n","import matplotlib.pyplot as plt\n","\n","# load data\n","data = genfromtxt('data.csv', delimiter=',')\n","\n","# X_b chứa thêm bias (=1)\n","m = 4\n","X = data[:,0]\n","y = data[:,1]\n","X_b = np.c_[np.ones((m, 1)), X]\n","\n","n_epochs = 30\n","thetas = np.array([[0.04],[-0.34]])\n","\n","thetas_path = [thetas]\n","losses = []\n","\n","for epoch in range(n_epochs):\n","    for i in range(1):\n","        # lấy ngẫu nhiên 1 sample [0,m-1]\n","        random_index = i#np.random.randint(m)\n","        xi = X_b[random_index:random_index+1]\n","        yi = y[random_index:random_index+1]\n","                \n","        # tính output (o = x1*w1 + x2*w2)\n","        oi = xi.dot(thetas)\n","\n","        # tính loss li [l = (output - y)^2]\n","        li = (oi - yi)*(oi - yi)\n","\n","        # tính gradient cho loss\n","        g_li = 2*(oi - yi)\n","\n","        # tính gradient (g_x1 = x1*g_li) va (g_x2 = x2*g_li)\n","        gradients = xi.T.dot(g_li)\n","        \n","        # tính learning rate cho mỗi sample\n","        eta = 0.01\n","\n","        # update giá trị theta\n","        thetas = thetas - eta*gradients\n","\n","        # logging\n","        thetas_path.append(thetas)            \n","        losses.append(li[0][0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M_4bpzqZPKm_"},"source":["Biểu đồ:"]},{"cell_type":"code","metadata":{"id":"ssOhCMpNPJIy"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(losses[1:])\n","plt.xlabel('iteration')\n","plt.ylabel('l')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jn6pktd1PRtj"},"source":[" "]},{"cell_type":"code","metadata":{"id":"XZtyrabQPNM4"},"source":["# random space\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import matplotlib.animation as animation\n","from IPython.display import HTML\n","from matplotlib.colors import LogNorm\n","from itertools import cycle\n","from numpy import genfromtxt\n","\n","\n","data = genfromtxt('data.csv', delimiter=',')\n","m = 4\n","X = data[:,0]\n","y = data[:,1]\n","X_b = np.c_[np.ones((m, 1)), X]\n","\n","eta = 0.01\n","index = 0\n","thetas = np.array([[0.04],[-0.34]])\n","\n","losses = []\n","\n","def compute_gradient(index):\n","    global thetas\n","    global losses\n","    \n","    xi = X_b[index:index+1]\n","    yi = y[index:index+1]\n","    \n","    oi = xi.dot(thetas)\n","    li = (oi - yi)*(oi - yi)\n","    \n","    losses.append(li[0][0])\n","    #print(xi, yi)\n","    #print('\\n loss: ', li)\n","    \n","    g_li = 2*(oi - yi)\n","    gradients = xi.T.dot(g_li)\n","    \n","    thetas = thetas - eta*gradients\n","    \n","    a = thetas[1][0]\n","    b = thetas[0][0]\n","    \n","    return a,b\n","\n","def update_plot(i): \n","    plt.cla()\n","    \n","    global index\n","    global thetas\n","    \n","    index = index+1\n","    index = index%m\n","    #print(index)\n","    \n","    a,b = compute_gradient(index)\n","    #print(a,b)\n","    \n","    plt.scatter(areas, prices)\n","    x_value = np.arange(3,8)\n","\n","    y_value = a*x_value + b \n","    plt.plot(x_value, y_value,c='red')\n","\n","    plt.xlabel('Diện tích nhà (x 100$m^2$)')\n","    plt.ylabel('Giá nhà (chục lượng vàng)')\n","    \n","    plt.xlim(2,8)\n","    plt.ylim(3,10)\n","\n","fig, ax = plt.subplots(figsize=(8, 5))\n","a,b = compute_gradient(index)\n","\n","plt.scatter(areas, prices)\n","x_value = np.arange(3,8)\n","\n","y_value = a*x_value + b \n","plt.plot(x_value, y_value,c='red')\n","\n","plt.xlabel('Diện tích nhà (x 100$m^2$)')\n","plt.ylabel('Giá nhà (chục lượng vàng)')\n","\n","plt.xlim(2,8)\n","plt.ylim(3,10)\n","\n","#plt.show()\n","ani = animation.FuncAnimation(fig, update_plot, interval=2000, frames=range(30), fargs=())    \n","#HTML(ani.to_html5_video())\n","ani.save('chap6_data_gif_2.gif', writer='imagemagick', fps=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DS6idxB8PWcy"},"source":["Biểu đồ:"]},{"cell_type":"code","metadata":{"id":"kUg4FYxTPUe0"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(losses[1:])\n","plt.xlabel('iteration')\n","plt.ylabel('losses')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AopFl3mfOn67"},"source":["####**Simple linear regression _ minibatch**"]},{"cell_type":"markdown","metadata":{"id":"OQYWYp4yPgfE"},"source":["Tạo ngẫu nhiên các điểm:"]},{"cell_type":"code","metadata":{"id":"cgilGRJSPd4R"},"source":["# b=0.2 \n","# a=1.2\n","import numpy as np\n","from numpy import genfromtxt\n","import matplotlib.pyplot as plt\n","\n","data = genfromtxt('data.csv', delimiter=',')\n","areas  = data[:,0]\n","prices = data[:,1]\n","\n","\n","# X_b chứa thêm bias (=1)\n","m=4\n","X = data[:,0]\n","y = data[:,1:]\n","X_b = np.c_[np.ones((m, 1)), X]\n","\n","print('X_b', X_b)\n","print('y', y)\n","\n","plt.scatter(areas, prices)\n","plt.xlabel('areas')\n","plt.ylabel('prices')\n","plt.xlim(3,7)\n","plt.ylim(4,10)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9j_48BSLPovI"},"source":[""]},{"cell_type":"code","metadata":{"id":"yEcUXQzOPkqz"},"source":["# random space\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import matplotlib.animation as animation\n","from IPython.display import HTML\n","from matplotlib.colors import LogNorm\n","from itertools import cycle\n","from numpy import genfromtxt\n","\n","\n","data = genfromtxt('data.csv', delimiter=',')\n","m = 4\n","X = data[:,0]\n","y = data[:,1]\n","X_b = np.c_[np.ones((m, 1)), X]\n","\n","eta = 0.01\n","index = 0\n","thetas = np.array([[0.04],[-0.34]])\n","\n","losses = []\n","\n","def compute_gradient():\n","    global thetas\n","    global losses\n","    \n","    sum_of_losses = 0\n","    gradients = np.zeros((2,1))\n","    \n","    for _ in range(2):\n","        index = random.randint(0, 3)\n","        xi = X_b[index:index+1]\n","        yi = y[index:index+1]\n","\n","        oi = xi.dot(thetas)\n","        li = (oi - yi)*(oi - yi)\n","        \n","        g_li = 2*(oi - yi)\n","        \n","        gradients = gradients + xi.T.dot(g_li)\n","        sum_of_losses = sum_of_losses + li\n","    \n","    sum_of_losses = sum_of_losses/2\n","    gradients     = gradients/2\n","    losses.append(sum_of_losses[0][0]) \n","    \n","    thetas = thetas - eta*gradients\n","    \n","    a = thetas[1][0]\n","    b = thetas[0][0]\n","    \n","    return a,b\n","\n","def update_plot(i): \n","    plt.cla()\n","    \n","    global thetas    \n","    a,b = compute_gradient()\n","    \n","    plt.scatter(areas, prices)\n","    x_value = np.arange(3,8)\n","\n","    y_value = a*x_value + b \n","    plt.plot(x_value, y_value,c='red')\n","\n","    plt.xlabel('areas')\n","    plt.ylabel('prices')\n","    \n","    plt.xlim(2,8)\n","    plt.ylim(3,10)\n","\n","fig, ax = plt.subplots(figsize=(8, 5))\n","a,b = compute_gradient()\n","\n","plt.scatter(areas, prices)\n","x_value = np.arange(3,8)\n","\n","y_value = a*x_value + b \n","plt.plot(x_value, y_value,c='red')\n","\n","plt.xlabel('areas')\n","plt.ylabel('prices')\n","\n","plt.xlim(2,8)\n","plt.ylim(3,10)\n","\n","#plt.show()\n","ani = animation.FuncAnimation(fig, update_plot, interval=2000, frames=range(30), fargs=())    \n","#HTML(ani.to_html5_video())\n","ani.save('chap6_data_gif_4.gif', writer='imagemagick', fps=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yds6qMdSPr9D"},"source":["Biểu đồ:"]},{"cell_type":"code","metadata":{"id":"j7R3Btu5Prei"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(losses[1:])\n","plt.xlabel('iteration')\n","plt.ylabel('losses')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oNZpC8EqPwi_"},"source":[""]},{"cell_type":"code","metadata":{"id":"IePmQ1fkPxEc"},"source":["import numpy as np\n","from numpy import genfromtxt\n","import matplotlib.pyplot as plt\n","\n","data = genfromtxt('data.csv', delimiter=',')\n","\n","# X_b chứa thêm bias (=1)\n","m=4\n","X = data[:,0]\n","y = data[:,1:]\n","X_b = np.c_[np.ones((m, 1)), X]\n","\n","n_epochs = 1\n","eta = 0.01\n","thetas = np.array([[0.04],[-0.34]])\n","#thetas = np.array([[0.26676], [1.179292]])\n","#thetas = np.array([[0.28539967], [1.3041778]])\n","print('thetas', thetas)\n","\n","thetas_path = [thetas]\n","losses = []\n","\n","for epoch in range(n_epochs):\n","    sum_of_losses = 0\n","    gradients = np.zeros((2,1))\n","    \n","    for index in range(2):\n","        xi = X_b[index:index+1]\n","        yi = y[index:index+1]\n","        \n","        print('\\ndata: ', xi, yi)\n","\n","        oi = xi.dot(thetas)\n","        li = (oi - yi)*(oi - yi)        \n","        g_li = 2*(oi - yi)\n","        \n","        print('\\n\\n z: ', oi)\n","        print('loss: ', index, li)\n","        print('gradient_loss: ', index, g_li)\n","        \n","        cg = xi.T.dot(g_li)\n","        print('variable gradient: ', index, cg)\n","        \n","        gradients = gradients + cg\n","        sum_of_losses = sum_of_losses + li\n","    \n","    sum_of_losses = sum_of_losses/2\n","    gradients     = gradients/2\n","    print('\\ngradients: ', gradients)\n","    losses.append(sum_of_losses[0][0]) \n","        \n","    thetas = thetas - eta*gradients\n","    print('new params: ', thetas)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gNqftjvWOvXx"},"source":["####**Simple linear regression _ batch**"]},{"cell_type":"markdown","metadata":{"id":"4K5XheOPP3UC"},"source":["Tạo ngẫu nhiên các điểm:"]},{"cell_type":"code","metadata":{"id":"TqFQwO2CP2ev"},"source":["import numpy as np\n","from numpy import genfromtxt\n","import matplotlib.pyplot as plt\n","\n","data = genfromtxt('data.csv', delimiter=',')\n","areas  = data[:,0]\n","prices = data[:,1]\n","\n","\n","# X_b chứa thêm bias (=1)\n","m=4\n","X = data[:,0]\n","y = data[:,1:]\n","X_b = np.c_[np.ones((m, 1)), X]\n","\n","print(X_b)\n","print(y)\n","\n","plt.scatter(areas, prices)\n","plt.xlabel('areas')\n","plt.ylabel('prices')\n","plt.xlim(3,7)\n","plt.ylim(4,10)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-MnxpVjxP83y"},"source":[""]},{"cell_type":"code","metadata":{"id":"Wv3aPEflP9RA"},"source":["# random space\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import matplotlib.animation as animation\n","from IPython.display import HTML\n","from matplotlib.colors import LogNorm\n","from itertools import cycle\n","from numpy import genfromtxt\n","\n","\n","data = genfromtxt('data.csv', delimiter=',')\n","m = 4\n","X = data[:,0]\n","y = data[:,1]\n","X_b = np.c_[np.ones((m, 1)), X]\n","\n","eta = 0.01\n","index = 0\n","thetas = np.array([[0.04],[-0.34]])\n","\n","losses = []\n","\n","def compute_gradient():\n","    global thetas\n","    global losses\n","    \n","    sum_of_losses = 0\n","    gradients = np.zeros((2,1))\n","    \n","    for index in range(4):\n","        xi = X_b[index:index+1]\n","        yi = y[index:index+1]\n","\n","        oi = xi.dot(thetas)\n","        li = (oi - yi)*(oi - yi)\n","        \n","        g_li = 2*(oi - yi)\n","        \n","        gradients = gradients + xi.T.dot(g_li)\n","        sum_of_losses = sum_of_losses + li\n","    \n","    sum_of_losses = sum_of_losses/4\n","    gradients     = gradients/4\n","    losses.append(sum_of_losses[0][0]) \n","    \n","    thetas = thetas - eta*gradients\n","    \n","    a = thetas[1][0]\n","    b = thetas[0][0]\n","    \n","    return a,b\n","\n","def update_plot(i): \n","    plt.cla()\n","    \n","    global thetas    \n","    a,b = compute_gradient()\n","    \n","    plt.scatter(areas, prices)\n","    x_value = np.arange(3,8)\n","\n","    y_value = a*x_value + b \n","    plt.plot(x_value, y_value,c='red')\n","\n","    plt.xlabel('areas')\n","    plt.ylabel('prices')\n","    \n","    plt.xlim(2,8)\n","    plt.ylim(3,10)\n","\n","fig, ax = plt.subplots(figsize=(8, 5))\n","a,b = compute_gradient()\n","\n","plt.scatter(areas, prices)\n","x_value = np.arange(3,8)\n","\n","y_value = a*x_value + b \n","plt.plot(x_value, y_value,c='red')\n","\n","plt.xlabel('areas')\n","plt.ylabel('prices')\n","\n","plt.xlim(2,8)\n","plt.ylim(3,10)\n","\n","#plt.show()\n","ani = animation.FuncAnimation(fig, update_plot, interval=2000, frames=range(30), fargs=())    \n","#HTML(ani.to_html5_video())\n","ani.save('chap6_data_gif_7t.gif', writer='imagemagick', fps=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"91JvbaHFQAEV"},"source":["Biểu đồ:"]},{"cell_type":"code","metadata":{"id":"YgBJcn9zQCde"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(losses[1:])\n","plt.xlabel('iteration')\n","plt.ylabel('losses')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KGCFFiXzQGUi"},"source":[""]},{"cell_type":"code","metadata":{"id":"GgSRhm-RQGot"},"source":["import numpy as np\n","from numpy import genfromtxt\n","import matplotlib.pyplot as plt\n","\n","data = genfromtxt('data.csv', delimiter=',')\n","\n","# X_b chứa thêm bias (=1)\n","m=4\n","X = data[:,0]\n","y = data[:,1:]\n","X_b = np.c_[np.ones((m, 1)), X]\n","\n","n_epochs = 1\n","eta = 0.01\n","thetas = np.array([[0.04],[-0.34]])\n","print('thetas', thetas)\n","\n","thetas_path = [thetas]\n","losses = []\n","\n","for epoch in range(n_epochs):\n","    sum_of_losses = 0\n","    gradients = np.zeros((2,1))\n","    \n","    for index in range(3,4):\n","        xi = X_b[0:index+1]\n","        yi = y[0:index+1]\n","        print('\\ndata: ', xi, yi)\n","\n","        oi = xi.dot(thetas)\n","        li = (oi - yi)*(oi - yi)        \n","        g_li = 2*(oi - yi)\n","        \n","        print('z: ', oi)\n","        print('loss: ', index, li)\n","        print('gradient_loss: ', index, g_li)\n","        \n","        cg = xi.T.dot(g_li)\n","        print('variable gradient: ', index, cg)\n","        \n","        gradients = gradients + cg\n","        sum_of_losses = sum_of_losses + li\n","    \n","    sum_of_losses = sum_of_losses/1\n","    print('\\nsum_of_losses: ', sum_of_losses)\n","    gradients     = gradients/1\n","    print('\\ngradients: ', gradients)\n","    losses.append(sum_of_losses[0][0]) \n","    \n","    thetas = thetas - eta*gradients\n","    print('new params: ', thetas)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P3xGguuoQIqt"},"source":["import numpy as np\n","from numpy import genfromtxt\n","import matplotlib.pyplot as plt\n","\n","# Data preparation\n","data = genfromtxt('data.csv', delimiter=',')\n","N=4\n","X,y = data[:,0],data[:,1:]\n","\n","# vectorization\n","X_b = np.c_[np.ones((N, 1)), X]\n","\n","# parameters\n","thetas = np.array([[0.04],[-0.34]])\n","\n","n_epochs = 1\n","learning_rate = 0.01\n","for epoch in range(n_epochs):\n","    gradient_sum = np.zeros((2,1))\n","    loss_sum = 0.0\n","    \n","    for index in range(4):\n","        # pick sample\n","        x_i = X_b[index:index+1]\n","        y_i = y[index:index+1]\n","\n","        # output\n","        output_i = x_i.dot(thetas)\n","        \n","        # loss\n","        loss_i = (output_i - y_i)*(output_i - y_i)\n","        loss_sum = loss_sum + loss_i\n","        \n","        #gradient\n","        gradient_loss_i = x_i.T.dot(2*(output_i - y_i))        \n","        gradient_sum = gradient_sum + gradient_loss_i            \n","    \n","    thetas = thetas - learning_rate*(gradient_sum/N)\n","    print('new params: \\n', thetas)\n","    print('loss_sum: \\n', loss_sum/N)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7bx_8-71O1Cl"},"source":["####**Linear regression _ advertising**"]},{"cell_type":"code","metadata":{"id":"wYNEjW8GQVMH"},"source":["# dataset\n","import numpy as np\n","from numpy import genfromtxt\n","import matplotlib.pyplot as plt\n","\n","data = genfromtxt('advertising.csv', delimiter=',', skip_header=1)\n","\n","m = data.shape[0]\n","X = data[:,:3]\n","y = data[:,3:]\n","\n","maxi = np.max(X)\n","mini = np.min(X)\n","avg = np.mean(X)\n","X = (X-avg) / (maxi-mini)\n","\n","X_b = np.c_[np.ones((m, 1)), X]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lhn_souKQWTh"},"source":["def stochastic_gradient_descent():\n","    n_epochs = 50\n","    learning_rate = 0.01\n","    \n","    # khởi tạo giá trị tham số\n","    thetas = np.random.randn(4, 1)\n","    \n","    thetas_path = [thetas]\n","    losses = []\n","    \n","    for epoch in range(n_epochs):\n","        for i in range(m):\n","            # lấy ngẫu nhiên 1 sample\n","            random_index = np.random.randint(m)\n","            xi = X_b[random_index:random_index+1]\n","            yi = y[random_index:random_index+1]\n","            \n","            # tính output \n","            oi = xi.dot(thetas)\n","            \n","            # tính loss li\n","            li = (oi - yi)*(oi - yi) / 2\n","            \n","            # tính gradient cho loss\n","            g_li = (oi - yi)\n","            \n","            # tính gradient \n","            gradients = xi.T.dot(g_li)\n","                        \n","            # update giá trị theta\n","            thetas = thetas - learning_rate*gradients\n","            \n","            # logging\n","            thetas_path.append(thetas)            \n","            losses.append(li[0][0])\n","\n","    return thetas_path, losses\n","\n","bgd_thetas, losses = stochastic_gradient_descent()\n","\n","# in loss cho 500 sample đầu\n","x_axis = list(range(500))\n","plt.plot(x_axis,losses[:500], color=\"r\")\n","plt.show()\n","\n","#print(losses[:100])\n","\n","#plt.scatter(X, y)\n","#data_y = X*bgd_thetas[-1][1]+ bgd_thetas[-1][0]\n","#plt.plot(X,data_y, color=\"r\")\n","#plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DNrFxuWCQctK"},"source":["Biểu đồ:"]},{"cell_type":"code","metadata":{"id":"0wE1g_8PQZ2Q"},"source":["def mini_batch_gradient_descent():\n","    n_iterations = 50\n","    minibatch_size = 20\n","    \n","    thetas = np.random.randn(4, 1)\n","    thetas_path = [thetas]    \n","    losses = []\n","    \n","    for epoch in range(n_iterations):\n","        shuffled_indices = np.random.permutation(m)\n","        X_b_shuffled = X_b[shuffled_indices]\n","        y_shuffled = y[shuffled_indices]\n","                \n","        for i in range(0, m, minibatch_size):\n","            xi = X_b_shuffled[i:i+minibatch_size]\n","            yi = y_shuffled[i:i+minibatch_size]\n","            \n","            # tính output \n","            output = xi.dot(thetas)\n","            \n","            # tính loss\n","            loss = (output - yi)**2\n","            \n","            # tính đạo hàm cho loss\n","            loss_grd = 2*(output - yi)/minibatch_size\n","            \n","            # tính đạo hàm cho các tham số\n","            gradients = xi.T.dot(loss_grd)\n","            \n","            # cập nhật tham số\n","            learning_rate = 0.01\n","            thetas = thetas - learning_rate*gradients\n","            thetas_path.append(thetas)\n","            \n","            loss_mean = np.sum(loss)/minibatch_size\n","            losses.append(loss_mean)\n","\n","    return thetas_path, losses\n","\n","mbgd_thetas, losses = mini_batch_gradient_descent()\n","\n","# in loss cho 100 sample đầu\n","x_axis = list(range(200))\n","plt.plot(x_axis,losses[:200], color=\"r\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HacASOgOQfQy"},"source":["def batch_gradient_descent():\n","    n_iterations = 100\n","    learning_rate = 0.01\n","    \n","    # khởi tạo giá trị tham số\n","    thetas = np.random.randn(4, 1)\n","    thetas_path = [thetas]\n","    losses = []\n","    \n","    for i in range(n_iterations):\n","        # tính output\n","        output = X_b.dot(thetas)\n","        \n","        # tính loss\n","        loss = (output - y)**2        \n","                \n","        # tính đạo hàm cho loss\n","        loss_grd = 2*(output - y)/m\n","        \n","        # tính đạo hàm cho các tham số\n","        gradients = X_b.T.dot(loss_grd)\n","        \n","        # cập nhật tham số\n","        thetas = thetas - learning_rate*gradients\n","        thetas_path.append(thetas)\n","        \n","        mean_loss = np.sum(loss)/m\n","        losses.append(mean_loss)\n","\n","    return thetas_path, losses\n","\n","bgd_thetas, losses = batch_gradient_descent()\n","\n","# in loss cho 100 sample đầu\n","x_axis = list(range(100))\n","plt.plot(x_axis,losses[:100], color=\"r\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bDWMD0OoO7MF"},"source":["####**Linear regression - boston house**"]},{"cell_type":"code","metadata":{"id":"w9sZjK92Qi7d"},"source":["# data\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","data = pd.read_csv('BostonHousing.csv')\n","\n","def normal(x:list):\n","    maxi = max(x)\n","    mini = min(x)\n","    avg = np.mean(x)\n","    new = [(i-avg)/(maxi-mini) for i in x ]\n","    \n","    return new\n","\n","df = data.copy()\n","df = df.apply(normal, axis=0)\n","\n","Xd = df.drop(columns=['medv'])\n","Xd.insert(0, 'X0', 1) # bias \n","\n","# numpy array format\n","y = df.medv.values\n","y = np.expand_dims(y, axis=1)\n","\n","X_b = Xd.values\n","\n","# sample size\n","m = len(df.index)\n","n = X_b.shape[1]\n","theta = np.ones(n)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e2E9_x9bQuES"},"source":[""]},{"cell_type":"code","metadata":{"id":"5Jvi7EOQQtWI"},"source":["def normal(x:list):\n","    maxi = max(x)\n","    mini = min(x)\n","    avg = np.mean(x)\n","    new = [(i-avg)/(maxi-mini) for i in x ]\n","    \n","    return new\n","\n","df = data.copy()\n","df = df.apply(normal, axis=0)\n","\n","Xd = df.drop(columns=['medv'])\n","Xd.insert(0, 'X0', 1) # bias \n","\n","# numpy array format\n","y = df.medv.values\n","y = np.expand_dims(y, axis=1)\n","\n","X_b = Xd.values\n","\n","# sample size\n","m = len(df.index)\n","n = X_b.shape[1]\n","theta = np.ones(n)\n","\n","\n","print(X_b.shape)\n","print(y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uJPfEWIxQqHW"},"source":["Biểu đồ:"]},{"cell_type":"code","metadata":{"id":"oYofHwTOQvM-"},"source":["def batch_gradient_descent():\n","    n_iterations = 500\n","    learning_rate = 0.01\n","    \n","    # khởi tạo giá trị tham số\n","    thetas = np.random.randn(14, 1)\n","    thetas_path = [thetas]\n","    losses = []\n","    \n","    for i in range(n_iterations):\n","        # tính output\n","        output = X_b.dot(thetas)\n","        \n","        # tính loss\n","        loss = (output - y)**2        \n","                \n","        # tính đạo hàm cho loss\n","        loss_grd = 2*(output - y)/m\n","        \n","        # tính đạo hàm cho các tham số\n","        gradients = X_b.T.dot(loss_grd)\n","        \n","        # cập nhật tham số\n","        thetas = thetas - learning_rate*gradients\n","        thetas_path.append(thetas)\n","        \n","        mean_loss = np.sum(loss)/m\n","        losses.append(mean_loss)\n","\n","    return thetas_path, losses\n","\n","bgd_thetas, losses = batch_gradient_descent()\n","\n","# in loss cho 100 sample đầu\n","x_axis = list(range(500))\n","plt.plot(x_axis,losses[:500], color=\"r\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gdOx9IkEQ1b4"},"source":["def mini_batch_gradient_descent():\n","    n_iterations = 200\n","    minibatch_size = 64\n","    \n","    thetas = np.random.randn(14, 1)\n","    thetas_path = [thetas]    \n","    losses = []\n","    \n","    for epoch in range(n_iterations):\n","        shuffled_indices = np.random.permutation(m)\n","        X_b_shuffled = X_b[shuffled_indices]\n","        y_shuffled = y[shuffled_indices]\n","                \n","        for i in range(0, m, minibatch_size):\n","            xi = X_b_shuffled[i:i+minibatch_size]\n","            yi = y_shuffled[i:i+minibatch_size]\n","            \n","            # tính output \n","            output = xi.dot(thetas)\n","            \n","            # tính loss\n","            loss = (output - yi)**2\n","            \n","            # tính đạo hàm cho loss\n","            loss_grd = 2*(output - yi)/minibatch_size\n","            \n","            # tính đạo hàm cho các tham số\n","            gradients = xi.T.dot(loss_grd)\n","            \n","            # cập nhật tham số\n","            learning_rate = 0.01\n","            thetas = thetas - learning_rate*gradients\n","            thetas_path.append(thetas)\n","            \n","            loss_mean = np.sum(loss)/minibatch_size\n","            losses.append(loss_mean)\n","\n","    return thetas_path, losses\n","\n","mbgd_thetas, losses = mini_batch_gradient_descent()\n","\n","# in loss cho 100 sample đầu\n","x_axis = list(range(100))\n","plt.plot(x_axis,losses[:100], color=\"r\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a_O14YgTQ38D"},"source":["def stochastic_gradient_descent():\n","    n_epochs = 50\n","    learning_rate = 0.01\n","    \n","    # khởi tạo giá trị tham số\n","    thetas = np.random.randn(14, 1)\n","    \n","    thetas_path = [thetas]\n","    losses = []\n","    \n","    for epoch in range(n_epochs):\n","        for i in range(m):\n","            # lấy ngẫu nhiên 1 sample\n","            random_index = np.random.randint(m)\n","            xi = X_b[random_index:random_index+1]\n","            yi = y[random_index:random_index+1]\n","            \n","            # tính output \n","            oi = xi.dot(thetas)\n","            \n","            # tính loss li\n","            li = (oi - yi)*(oi - yi) / 2\n","            \n","            # tính gradient cho loss\n","            g_li = (oi - yi)\n","            \n","            # tính gradient \n","            gradients = xi.T.dot(g_li)\n","                        \n","            # update giá trị theta\n","            thetas = thetas - learning_rate*gradients\n","            \n","            # logging\n","            thetas_path.append(thetas)            \n","            losses.append(li[0][0])\n","\n","    return thetas_path, losses\n","\n","bgd_thetas, losses = stochastic_gradient_descent()\n","\n","# in loss cho 100 sample đầu\n","x_axis = list(range(100))\n","plt.plot(x_axis,losses[:100], color=\"r\")\n","plt.show()\n","\n","#print(losses[:100])\n","\n","#plt.scatter(X, y)\n","#data_y = X*bgd_thetas[-1][1]+ bgd_thetas[-1][0]\n","#plt.plot(X,data_y, color=\"r\")\n","#plt.show()"],"execution_count":null,"outputs":[]}]}